{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "sys.path.append('../')  \n",
    "\n",
    "from Models.alexnet import AlexNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Settings \n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the modified training set: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "Unique labels in the modified test set: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "class MNISTNoZero(datasets.MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MNISTNoZero, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Filter out indices of all '0' digits\n",
    "        self.non_zero_indices = [i for i, target in enumerate(self.targets) if target != 0]\n",
    "        \n",
    "        # Keep only the data and targets that are not '0'\n",
    "        self.data = self.data[self.non_zero_indices]\n",
    "        self.targets = self.targets[self.non_zero_indices] - 1\n",
    "\n",
    "\n",
    "# Normalization transform\n",
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#Use to get the '0' digits\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_normalize)\n",
    "\n",
    "# Create training and test datasets without '0' digits\n",
    "mnist_trainset_no_zero = MNISTNoZero(root='./data', train=True, download=True, transform=transform_normalize)\n",
    "\n",
    "mnist_testset_no_zero = MNISTNoZero(root='./data', train=False, download=True, transform=transform_normalize)\n",
    "classes = ('1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "\n",
    "# Verify by checking the unique labels in the modified datasets\n",
    "print(\"Unique labels in the modified training set:\", mnist_trainset_no_zero.targets.unique())\n",
    "print(\"Unique labels in the modified test set:\", mnist_testset_no_zero.targets.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(mnist_trainset_no_zero, [45077, 9000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "# good\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset_no_zero, batch_size=64,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=64,\n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task='multiclass', num_classes=9)\n",
    "\n",
    "accuracy = accuracy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet = AlexNet(num_classes=9, channels=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_adam = optim.Adam(model_alexnet.parameters(), lr=1e-4)\n",
    "optimizer_sgd = torch.optim.SGD(model_alexnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "AlexNet (AlexNet)                        [1, 1, 224, 224]     [1, 9]               --                   True\n",
       "├─Sequential (features)                  [1, 1, 224, 224]     [1, 256, 6, 6]       --                   True\n",
       "│    └─Conv2d (0)                        [1, 1, 224, 224]     [1, 64, 55, 55]      7,808                True\n",
       "│    └─ReLU (1)                          [1, 64, 55, 55]      [1, 64, 55, 55]      --                   --\n",
       "│    └─MaxPool2d (2)                     [1, 64, 55, 55]      [1, 64, 27, 27]      --                   --\n",
       "│    └─Conv2d (3)                        [1, 64, 27, 27]      [1, 192, 27, 27]     307,392              True\n",
       "│    └─ReLU (4)                          [1, 192, 27, 27]     [1, 192, 27, 27]     --                   --\n",
       "│    └─MaxPool2d (5)                     [1, 192, 27, 27]     [1, 192, 13, 13]     --                   --\n",
       "│    └─Conv2d (6)                        [1, 192, 13, 13]     [1, 384, 13, 13]     663,936              True\n",
       "│    └─ReLU (7)                          [1, 384, 13, 13]     [1, 384, 13, 13]     --                   --\n",
       "│    └─Conv2d (8)                        [1, 384, 13, 13]     [1, 256, 13, 13]     884,992              True\n",
       "│    └─ReLU (9)                          [1, 256, 13, 13]     [1, 256, 13, 13]     --                   --\n",
       "│    └─Conv2d (10)                       [1, 256, 13, 13]     [1, 256, 13, 13]     590,080              True\n",
       "│    └─ReLU (11)                         [1, 256, 13, 13]     [1, 256, 13, 13]     --                   --\n",
       "│    └─MaxPool2d (12)                    [1, 256, 13, 13]     [1, 256, 6, 6]       --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [1, 256, 6, 6]       [1, 256, 6, 6]       --                   --\n",
       "├─Sequential (classifier)                [1, 9216]            [1, 9]               --                   True\n",
       "│    └─Dropout (0)                       [1, 9216]            [1, 9216]            --                   --\n",
       "│    └─Linear (1)                        [1, 9216]            [1, 4096]            37,752,832           True\n",
       "│    └─ReLU (2)                          [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Dropout (3)                       [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Linear (4)                        [1, 4096]            [1, 4096]            16,781,312           True\n",
       "│    └─ReLU (5)                          [1, 4096]            [1, 4096]            --                   --\n",
       "│    └─Linear (6)                        [1, 4096]            [1, 9]               36,873               True\n",
       "========================================================================================================================\n",
       "Total params: 57,025,225\n",
       "Trainable params: 57,025,225\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 663.77\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 3.95\n",
       "Params size (MB): 228.10\n",
       "Estimated Total Size (MB): 232.25\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model_alexnet, input_size=(1, 1, 224, 224), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the loss and accuracy\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "experiment_name = f'AlexNet_One_to_Nine_{timestamp}'\n",
    "model_name = 'AlexNet_v1'\n",
    "log_dir = os.path.join('runs', timestamp, experiment_name, model_name)\n",
    "log_writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "    train_loss, train_acc = 0, 0\n",
    "    cumulative_batch = 0\n",
    "\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    for X, y in trainloader:\n",
    "        \n",
    "        model_alexnet.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        cumulative_batch += BATCH_SIZE\n",
    "        print(f'Batch {cumulative_batch} / 50000')\n",
    "\n",
    "        y_pred = model_alexnet(X)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f'Loss: {loss.item()}')\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        acc = accuracy(y_pred, y)\n",
    "        train_acc += acc\n",
    "        print(f'Loss: {train_loss}, Accuracy: {acc}')\n",
    "\n",
    "        optimizer_adam.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_adam.step()\n",
    "    \n",
    "    train_loss /= len(trainloader)\n",
    "    train_acc /= len(trainloader)\n",
    "\n",
    "    val_loss, val_acc = 0, 0\n",
    "    model_alexnet.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in valloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model_alexnet(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_loss += loss.item()\n",
    "            acc = accuracy(y_pred, y)\n",
    "            val_acc += acc\n",
    "            print(f'Val Loss: {val_loss}, Val Accuracy: {acc}')\n",
    "        \n",
    "        val_loss /= len(valloader)\n",
    "        val_acc /= len(valloader)\n",
    "\n",
    "\n",
    "    log_writer.add_scalars(main_tag=\"Loss\", tag_scalar_dict={\"train/loss\": train_loss, \"val/loss\": val_loss}, global_step=epoch)\n",
    "    log_writer.add_scalars(main_tag=\"Accuracy\", tag_scalar_dict={\"train/acc\": train_acc, \"val/acc\": val_acc}, global_step=epoch)\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
