{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings \n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.131), (0.308))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                download=True, transform=transform_normalize)\n",
    "\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                 download=True, transform=transform_normalize)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=4,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.stack([sample[0] for sample in ConcatDataset([mnist_trainset])])\n",
    "\n",
    "x_test = torch.stack([sample[0] for sample in ConcatDataset([mnist_testset])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show image of shape (1, 28, 28)\n",
    "\n",
    "def imshow(img):\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(x_train[0:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5\n",
    "### for MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x, return_intermediate=False):\n",
    "        outputs = {}\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        outputs['conv1'] = x\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        outputs['conv2'] = x\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        outputs['flatten'] = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        outputs['fc1'] = x\n",
    "        x = F.relu(self.fc2(x))\n",
    "        outputs['fc2'] = x\n",
    "        x = self.fc3(x)\n",
    "        outputs['fc3'] = x\n",
    "\n",
    "        if return_intermediate:\n",
    "            return outputs, x\n",
    "        else:\n",
    "            return  x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass single image through the network\n",
    "net = LeNet()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass single image through the network\n",
    "outs, x_out = net(x_train[0].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 1 - Conv2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = outs['conv1'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, len(feature_maps[0]), figsize=(12, 6))\n",
    "for idx, feature_map in enumerate(feature_maps[0]):\n",
    "    axes[idx].imshow(feature_map, cmap='gray')\n",
    "    axes[idx].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 2 - Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_maps = outs['conv2'].detach().cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(feature_maps[0]), figsize=(12, 6))\n",
    "for idx, feature_map in enumerate(feature_maps[0]):\n",
    "    axes[idx].imshow(feature_map, cmap='gray')\n",
    "    axes[idx].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36mLeNet.forward\u001b[1;34m(self, x, return_intermediate)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, return_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     15\u001b[0m     outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mm:\\ML\\ML_regs\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  # Move inputs and labels to the correct device\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
