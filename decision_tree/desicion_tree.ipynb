{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import desicion_tree as dt\n",
    "# Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Decision tree classifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a dataframe with the four feature variables\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# View the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df, iris.target\n",
    "x = x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = dt.DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_e  = dtree.entropy(y)\n",
    "total_e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ev  = dtree.entropy_v(y)\n",
    "total_ev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_index:  0\n",
      "feature_index:  1\n",
      "feature_index:  2\n",
      "feature_index:  3\n"
     ]
    }
   ],
   "source": [
    "# test best_split function that takes y, number of samples and feature\n",
    "\n",
    "bt = dtree.best_split(x, 150, x.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gain': 0.9988455359952022,\n",
       " 'feature': 3,\n",
       " 'threshold': 1.3,\n",
       " 'left_dataset': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3]]),\n",
       " 'right_dataset': array([[7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(150,)\n",
      "1\n",
      "(150,)\n",
      "2\n",
      "(150,)\n",
      "3\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "for f in range(x.shape[1]):\n",
    "    print(f)\n",
    "    print(x[:,f].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.01063111265619332\n",
      "0.0429233488131886\n",
      "0.05355446146938192\n",
      "0.09688418458795489\n",
      "0.11827815796913366\n",
      "0.17278859375790545\n",
      "0.18672735774501525\n",
      "0.24788611152544293\n",
      "0.31674766495245654\n",
      "0.3378419642396884\n",
      "0.3484730768958817\n",
      "0.38728655393459577\n",
      "0.422255412781825\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2\n",
      "0.01063111265619332\n",
      "0.02126222531238664\n",
      "0.042656198693565406\n",
      "0.1199747145504082\n",
      "0.2696372028725742\n",
      "0.4192996911947402\n",
      "0.496618207051583\n",
      "0.539947930170156\n",
      "0.5613419035513347\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "3\n",
      "0.054510435788771794\n",
      "0.43575182414726443\n",
      "0.5130703400041072\n",
      "0.59038885586095\n",
      "0.6010199685171433\n",
      "0.6116510811733367\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "None 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\ML\\ML_regs\\decision_tree\\desicion_tree.py:28: RuntimeWarning: divide by zero encountered in log2\n"
     ]
    }
   ],
   "source": [
    "n_features = x.shape[1]\n",
    "best_info_gain = 0\n",
    "best_feature = None\n",
    "for f in range(n_features):\n",
    "    print(f)\n",
    "    unique_values = np.unique(x[:, f])\n",
    "    new_entropy = 0\n",
    "    for value in unique_values:\n",
    "        y_left = y[x[:, f] == value]\n",
    "        y_right = y[x[:, f] != value]\n",
    "\n",
    "        info_gain = dtree.information_gain(y, y_left, y_right)\n",
    "        new_entropy += info_gain\n",
    "        print(new_entropy)\n",
    "\n",
    "    if new_entropy > best_info_gain:\n",
    "        best_info_gain = new_entropy\n",
    "        best_feature = f\n",
    "    \n",
    "print(best_feature, best_info_gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = np.unique(x[:, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a decision tree classifier instance\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "model = clf.fit(x, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Decision Tree classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "        Maximum depth of the tree.\n",
    "    min_samples_split : int\n",
    "        Minimum samples in a node to consider split.\n",
    "    min_impurity : float\n",
    "        Minimum impurity to consider split.\n",
    "    max_features : int\n",
    "        Maximum number of features to consider for split.\n",
    "    criterion : string\n",
    "        Split criterion (\"entropy\" or \"gini\").\n",
    "    random_state : int\n",
    "        Random number generator seed for random weight initialization.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # def __init__(self, max_depth=10, min_samples_split=2, min_impurity=1e-7,\n",
    "    #              max_features=None, criterion='entropy', random_state=None):\n",
    "    #     self.max_depth = max_depth\n",
    "    #     self.min_samples_split = min_samples_split\n",
    "    #     self.min_impurity = min_impurity\n",
    "    #     self.max_features = max_features\n",
    "    #     self.criterion = criterion\n",
    "    #     self.random_state = random_state\n",
    "\n",
    "    #     # initialize the root of the tree and the list of possible features\n",
    "    #     self.tree = None\n",
    "    #     self.feature_indices = None\n",
    "\n",
    "    # def fit(self, X, y):\n",
    "    #     \"\"\"\n",
    "    #     Build decision tree.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     X : array-like, shape = [n_samples, n_features]\n",
    "    #         The training input samples.\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     self : object\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # initialize tree and possible feature indices\n",
    "    #     self.tree = {}\n",
    "    #     self.feature_indices = np.arange(X.shape[1])\n",
    "\n",
    "    #     # build tree\n",
    "    #     self._grow_tree(X, y)\n",
    "\n",
    "    #     return self\n",
    "\n",
    "    # def predict(self, X):\n",
    "    #     \"\"\"\n",
    "    #     Predict class for X.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     X : array-like, shape = [n_samples, n_features]\n",
    "    #         The input samples.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     y : array of shape = [n_samples]\n",
    "    #         The predicted classes.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    # def _grow_tree(self, X, y, depth=0):\n",
    "    #     \"\"\"\n",
    "    #     Build decision tree.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     X : array-like, shape = [n_samples, n_features]\n",
    "    #         The training input samples.\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "    #     depth : int\n",
    "    #         Current depth in the tree.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # find the best split\n",
    "    #     gain, split = self._find_split(X, y)\n",
    "\n",
    "    #     # no (further) split if information gain is 0\n",
    "    #     if gain == 0:\n",
    "    #         return\n",
    "\n",
    "    #     # split data\n",
    "    #     indices_left = X[:, split] < split\n",
    "    #     X_left, y_left = X[indices_left], y[indices_left]\n",
    "    #     X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "    #     # grow left and right child\n",
    "    #     depth += 1\n",
    "    #     self.tree[split] = {'left': self._grow_tree(X_left, y_left, depth),\n",
    "    #                         'right': self._grow_tree(X_right, y_right, depth)}\n",
    "\n",
    "    # def _find_split(self, X, y):\n",
    "    #     \"\"\"\n",
    "    #     Find split for the current node.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     X : array-like, shape = [n_samples, n_features]\n",
    "    #         The training input samples.\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     gain : float\n",
    "    #         Information gain.\n",
    "    #     split : int\n",
    "    #         Feature index of the split.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # initialize values\n",
    "    #     best_gain = -1\n",
    "    #     best_split = None\n",
    "    #     n_samples, n_features = X.shape\n",
    "    #     if self.max_features is None:\n",
    "    #         self.max_features = n_features\n",
    "\n",
    "    #     # select random features\n",
    "    #     np.random.seed(self.random_state)\n",
    "    #     self.feature_indices = np.random.choice(n_features, self.max_features, replace=False)\n",
    "\n",
    "    #     # loop over all (randomly selected) features\n",
    "    #     for feature in self.feature_indices:\n",
    "    #         # find split\n",
    "    #         split, gain = self._find_split_for_feature(X, y, feature)\n",
    "\n",
    "    #         # update best split if information gain is higher than the current best\n",
    "    #         if gain > best_gain:\n",
    "    #             best_gain, best_split = gain, split\n",
    "\n",
    "    #     return best_gain, best_split\n",
    "\n",
    "    # def _find_split_for_feature(self, X, y, feature):\n",
    "    #     \"\"\"\n",
    "    #     Find split for the current feature.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     X : array-like, shape = [n_samples, n_features]\n",
    "    #         The training input samples.\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "    #     feature : int\n",
    "    #         Feature index.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     split : int\n",
    "    #         Feature index of the split.\n",
    "    #     gain : float\n",
    "    #         Information gain.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # initialize values\n",
    "    #     best_gain = -1\n",
    "    #     split = None\n",
    "\n",
    "    #     # loop over all possible splits\n",
    "    #     for i in range(X.shape[0]):\n",
    "    #         # find information gain\n",
    "    #         gain = self._information_gain(y, X[:, feature], i)\n",
    "\n",
    "    #         # update best split if information gain is higher than the current best\n",
    "    #         if gain > best_gain:\n",
    "    #             best_gain, split = gain, i\n",
    "\n",
    "    #     return split, best_gain\n",
    "\n",
    "    # def _information_gain(self, y, X_column, split):\n",
    "    #     \"\"\"\n",
    "    #     Calculate information gain.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "    #     X_column : array-like, shape = [n_samples]\n",
    "    #         The feature values.\n",
    "    #     split : int\n",
    "    #         Feature index of the split.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     gain : float\n",
    "    #         Information gain.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # calculate parent entropy\n",
    "    #     parent_entropy = self._entropy(y)\n",
    "\n",
    "    #     # calculate weighted average of child entropy\n",
    "    #     left_entropy = self._entropy(y[X_column < X_column[split]])\n",
    "    #     right_entropy = self._entropy(y[X_column >= X_column[split]])\n",
    "    #     child_entropy = (left_entropy * sum(X_column < X_column[split]) + right_entropy * sum(X_column >= X_column[split])) / len(y)\n",
    "\n",
    "    #     # calculate information gain\n",
    "    #     gain = parent_entropy - child_entropy\n",
    "\n",
    "    #     return gain\n",
    "        \n",
    "    # def _entropy(self, y):\n",
    "    #     \"\"\"\n",
    "    #     Calculate entropy.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     y : array-like, shape = [n_samples]\n",
    "    #         The target values.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     entropy : float\n",
    "    #         Entropy.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # calculate class probabilities\n",
    "    #     probs = np.bincount(y) / len(y)\n",
    "\n",
    "    #     # calculate entropy\n",
    "    #     entropy = -probs.dot(np.log2(probs))\n",
    "\n",
    "    #     return entropy\n",
    "\n",
    "    # def _predict(self, inputs):\n",
    "    #     \"\"\"\n",
    "    #     Predict class for inputs.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     inputs : array-like, shape = [n_features]\n",
    "    #         The input sample.\n",
    "\n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     y : int\n",
    "    #         The predicted class.\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # loop until leaf is reached\n",
    "    #     split = list(self.tree.keys())[0]\n",
    "    #     while isinstance(self.tree[split], dict):\n",
    "    #         split = list(self.tree[split].keys())[inputs[split] < split]\n",
    "\n",
    "    #     return self.tree[split]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
